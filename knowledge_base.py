__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import os
import pandas as pd
from langchain.schema import Document
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from config import PDF_DOCS_DIR, CHROMA_PERSIST_DIR, EMBEDDING_MODEL_NAME, CHUNK_SIZE, CHUNK_OVERLAP
 
def load_documents_from_pdfs():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ PDF –∏–∑ –ø–∞–ø–∫–∏ pdf_docs –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    –ö–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç - –æ–±—ä–µ–∫—Ç langchain Document.
    """
    documents = []
    for filename in os.listdir(PDF_DOCS_DIR):
        if filename.lower().endswith(".pdf"):
            file_path = os.path.join(PDF_DOCS_DIR, filename)
            loader = PyPDFLoader(file_path)
            docs = loader.load()  # —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º)
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ ‚Äì –∏–º—è —Ñ–∞–π–ª–∞
            for doc in docs:
                doc.metadata["source"] = filename
            documents.extend(docs)
    return documents

def load_documents_from_excel(file_path: str):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç–∞—Ç—å–∏ –∏–∑ Excel-—Ñ–∞–π–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    –ö–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç ‚Äì –æ–±—ä–µ–∫—Ç LangChain Document —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞.
    """
    documents = []
    # –ß–∏—Ç–∞–µ–º Excel-—Ñ–∞–π–ª (–¥–≤–µ –∫–æ–ª–æ–Ω–∫–∏: —Ç–µ–º–∞ –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ)
    df = pd.read_excel(file_path)
    print("–†–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã",df.shape)
    for _, row in df.iterrows():
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–º—É –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (–ø—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ –Ω–∞ —Å–ª—É—á–∞–π –Ω–∞–ª–∏—á–∏—è —á–∏—Å–µ–ª/NaN)
        topic = str(row["–ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏"]) if "–ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏" in df.columns else str(row[df.columns[0]])
        content = str(row["–û–ø–∏—Å–∞–Ω–∏–µ"]) if "–û–ø–∏—Å–∞–Ω–∏–µ" in df.columns else str(row[df.columns[1]])
        # –°–æ–∑–¥–∞—ë–º –¥–æ–∫—É–º–µ–Ω—Ç —Å –Ω—É–∂–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        doc = Document(
            page_content=content,
            metadata={"source": f"—Å—Ç–∞—Ç—å—è —Å —Å–∞–π—Ç–∞ –ø–æ—Ä—Ç–∞–ª –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤: {topic}"}
        )
        documents.append(doc)
    return documents
 
def split_documents(documents):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ –±–æ–ª–µ–µ –º–µ–ª–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.
    """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size = CHUNK_SIZE,
        chunk_overlap = CHUNK_OVERLAP,
        separators=["\n\n", "\n", " ", ""]
    )
    docs_split = text_splitter.split_documents(documents)
    return docs_split
 
def build_vector_store():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç Chroma –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.
    """
    if os.path.exists(CHROMA_PERSIST_DIR) and os.listdir(CHROMA_PERSIST_DIR):
        print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π Chroma –∏–Ω–¥–µ–∫—Å...")
        return load_vector_store()

    print("üÜï –ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π...")
    documents = []
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ PDF (–ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ)
    documents.extend(load_documents_from_pdfs())
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ Excel, –µ—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    excel_path = "./arcticles.xls"
    if os.path.exists(excel_path):
        documents.extend(load_documents_from_excel(excel_path))
    # –†–∞–∑–±–∏–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞
    docs_split = split_documents(documents)
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)
    vector_store = Chroma.from_documents(
        docs_split, embedding=embeddings, persist_directory=CHROMA_PERSIST_DIR
    )
    vector_store.persist()
    print("‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")
    return vector_store


def load_vector_store():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–∞–Ω–µ–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ Chroma.
    """
    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)
    vector_store = Chroma(
        persist_directory=CHROMA_PERSIST_DIR,
        embedding_function=embeddings
    )
    return vector_store

if __name__ == "__main__":
    # –î–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: –∑–∞–ø—É—Å–∫ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    vs = build_vector_store()
    print(f"–ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω, —á–∏—Å–ª–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(vs._collection.get()['documents'])}")